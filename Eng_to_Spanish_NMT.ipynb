{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng_to_Spanish_NMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BossAyush07/Deep-Learning-Projects/blob/master/Eng_to_Spanish_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPVbMe6CpSlF"
      },
      "source": [
        "### Importing Important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt9mkJyie6fd"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "from google.colab import files\n",
        "from string import digits\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIyGvMaTgEkb"
      },
      "source": [
        "data_path = \"spa.txt\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlb7RMJzpcY4"
      },
      "source": [
        "## Understanding the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAQELIMEYGPC",
        "outputId": "d18d3c00-25db-4464-b6ee-19c2d791a375"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "XMlK1iahgJWu",
        "outputId": "91d41e7a-349d-4415-fadf-2a08b7690ac2"
      },
      "source": [
        "#Read the data\n",
        "lines_raw= pd.read_table(data_path,names=['source', 'target', 'comments'])\n",
        "lines_raw.sample(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>I was sad.</td>\n",
              "      <td>Estuve triste.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11950</th>\n",
              "      <td>I need the money.</td>\n",
              "      <td>Necesito la plata.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63824</th>\n",
              "      <td>The main valve is turned off.</td>\n",
              "      <td>La válvula principal está cerrada.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37415</th>\n",
              "      <td>Tom may have been sick.</td>\n",
              "      <td>Puede que Tom haya estado enfermo.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67603</th>\n",
              "      <td>Our summer is short, but warm.</td>\n",
              "      <td>Nuestro verano es corto, pero cálido.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               source  ...                                           comments\n",
              "698                        I was sad.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "11950               I need the money.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "63824   The main valve is turned off.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "37415         Tom may have been sick.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #7...\n",
              "67603  Our summer is short, but warm.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gdkkpsKpAVy",
        "outputId": "8cde3a5b-c76e-43d7-9afe-35214d880f4e"
      },
      "source": [
        "len(lines_raw)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzBfKTw6wdtY"
      },
      "source": [
        "###Clean and Preprocess the text\n",
        "\n",
        "Convert to lower case\n",
        "\n",
        "Convert special characters\n",
        "\n",
        "Remove Digits\n",
        "\n",
        "Remove spaces\n",
        "\n",
        "Add start and end tags to each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc4VWEYigSLv"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    #sentence = unicode_to_ascii(sentence.lower().strip())\n",
        "    num_digits= str.maketrans('','', digits)\n",
        "    \n",
        "    sentence= sentence.lower()\n",
        "    sentence= re.sub(\" +\", \" \", sentence)\n",
        "    sentence= re.sub(\"'\", '', sentence)\n",
        "    sentence= sentence.translate(num_digits)\n",
        "    sentence= sentence.strip()\n",
        "    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.rstrip().strip()\n",
        "    sentence=  'start_ ' + sentence + ' _end'\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P897anw7gs89",
        "outputId": "abb23497-57e7-4634-c886-7a66c060ef22"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start_ may i borrow this book ? _end\n",
            "b'start_ \\xc2\\xbf puedo tomar prestado este libro ? _end'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL4UKHz3gxIU"
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  \n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  #print(lines)\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
        "  print(path)\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FqkUZYpg1RO",
        "outputId": "556fb751-d425-4a68-9333-15aca663c2b0"
      },
      "source": [
        "sample_size=60000\n",
        "source, target = create_dataset(data_path, sample_size)\n",
        "print(source[-1])\n",
        "print(target[-1])\n",
        "type(target)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spa.txt\n",
            "start_ tom made himself a sandwich . _end\n",
            "start_ tom se hizo un sándwich . _end\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-EC7y4cg5Kb"
      },
      "source": [
        "def max_length(tensor):\n",
        "  return max(len(t) for t in tensor)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_mZ3mVDi_mz"
      },
      "source": [
        "###Create the source and target toekns and post pad them\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ7dUJsuibnV"
      },
      "source": [
        "source_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_sentence_tokenizer.fit_on_texts(source)\n",
        "source_tensor = source_sentence_tokenizer.texts_to_sequences(source)\n",
        "source_tensor= tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIWZ36WvjKXb",
        "outputId": "c1e48e02-a37b-479c-d5f5-eee53a3b9ca6"
      },
      "source": [
        "target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_sentence_tokenizer.fit_on_texts(target)\n",
        "target_tensor = target_sentence_tokenizer.texts_to_sequences(target)\n",
        "target_tensor= tf.keras.preprocessing.sequence.pad_sequences(target_tensor,padding='post' )\n",
        "print(len(target_tensor[0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSIzw0U2jTwr"
      },
      "source": [
        "###Creating Train and Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmHGo4v6jOxG"
      },
      "source": [
        "source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor= train_test_split(source_tensor, target_tensor,test_size=0.2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cb6AaThjYR6",
        "outputId": "8465e2bf-7b2d-4074-d432-a02ff1ba8187"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(source_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000 48000 12000 12000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNGAgnORjb8j",
        "outputId": "5769efb8-ff04-4665-f64f-b0471e6bcdca"
      },
      "source": [
        "type(input_tensor_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYaMC1QJjfGH"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IhO3RcgjiTa",
        "outputId": "631aa4c3-875d-4bbe-edbc-fb5756579793"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(source_sentence_tokenizer, source_train_tensor[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert( target_sentence_tokenizer, target_train_tensor[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> start_\n",
            "41 ----> they\n",
            "283 ----> felt\n",
            "13 ----> he\n",
            "19 ----> was\n",
            "84 ----> too\n",
            "1139 ----> weak\n",
            "3 ----> .\n",
            "2 ----> _end\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> start_\n",
            "60 ----> ellos\n",
            "4395 ----> sintieron\n",
            "12 ----> que\n",
            "16 ----> él\n",
            "79 ----> era\n",
            "113 ----> demasiado\n",
            "1364 ----> débil\n",
            "3 ----> .\n",
            "2 ----> _end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J82W96_Lj4dZ"
      },
      "source": [
        "###Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF1B9Z6wjmK2",
        "outputId": "27f8c26f-5210-4dba-b283-fe028dc5a17f"
      },
      "source": [
        "BUFFER_SIZE = len(source_train_tensor)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(source_train_tensor)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(source_sentence_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(target_sentence_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_train_tensor, target_train_tensor)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "type(dataset)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feyNakZHkAqj",
        "outputId": "4ef7b1ab-34c8-45b6-db4b-cd7359b927cb"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 13]), TensorShape([64, 20]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsNcD2ofkUAA"
      },
      "source": [
        "###Write the encoder and decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcWrZlCqkGlm"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgeFgUCcklSC",
        "outputId": "9a2a323e-24cc-46af-f725-bdf6f3bc4642"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 13, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OieJroz9kpGx"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuzW7RqGk6JB",
        "outputId": "d7e3a8ee-cdab-4bd9-9a28-4f7d85092ef0"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 13, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZjT1i-uk93k"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoblVzNBlDky",
        "outputId": "e0927524-dc70-4a12-898a-182c1a7e4913"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 15349)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5r92cTKlMci"
      },
      "source": [
        "##Define the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8In-MTOlHhE"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih0pan47lZDA"
      },
      "source": [
        "###Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1VHsCmAlRiq"
      },
      "source": [
        "checkpoint_dir = 'training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zDBsWO6xdCH"
      },
      "source": [
        "act = \"puede que tom hayaestado enfermo.\"\n",
        "pred = translatee(u'tom may have been sick.')"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF4wnLAflkmv"
      },
      "source": [
        "###Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-h_bAMDlmmw"
      },
      "source": [
        "Pass the input through the encoder which return encoder output and the encoder hidden state.\n",
        "\n",
        "The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n",
        "\n",
        "The decoder returns the predictions and the decoder hidden state.\n",
        "\n",
        "The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "\n",
        "Use teacher forcing to decide the next input to the decoder.\n",
        "\n",
        "Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
        "\n",
        "The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcqsV143ld0g"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WAZeyrTlxLj",
        "outputId": "0a288d58-3bea-401f-d842-5276f34e5e6e"
      },
      "source": [
        "steps_per_epoch"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0WGamull1NP",
        "outputId": "552386eb-2392-4bdc-b61d-3e7dec2229a6"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} loss {}'.format(epoch + 1,batch, batch_loss.numpy()))\n",
        "   \n",
        "      \n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 loss 2.929354190826416\n",
            "Epoch 1 Batch 100 loss 1.5624536275863647\n",
            "Epoch 1 Batch 200 loss 1.5000457763671875\n",
            "Epoch 1 Batch 300 loss 1.3340100049972534\n",
            "Epoch 1 Batch 400 loss 1.1841086149215698\n",
            "Epoch 1 Batch 500 loss 1.3030389547348022\n",
            "Epoch 1 Batch 600 loss 1.1054136753082275\n",
            "Epoch 1 Batch 700 loss 1.0727628469467163\n",
            "Epoch 1 Loss 1.3316\n",
            "Time taken for 1 epoch 126.24873304367065 sec\n",
            "\n",
            "Epoch 2 Batch 0 loss 0.97889244556427\n",
            "Epoch 2 Batch 100 loss 0.9670166969299316\n",
            "Epoch 2 Batch 200 loss 0.9076053500175476\n",
            "Epoch 2 Batch 300 loss 0.9308255314826965\n",
            "Epoch 2 Batch 400 loss 0.8875002264976501\n",
            "Epoch 2 Batch 500 loss 0.7491058707237244\n",
            "Epoch 2 Batch 600 loss 0.7226148843765259\n",
            "Epoch 2 Batch 700 loss 0.6775697469711304\n",
            "Epoch 2 Loss 0.8286\n",
            "Time taken for 1 epoch 106.21266174316406 sec\n",
            "\n",
            "Epoch 3 Batch 0 loss 0.6952165961265564\n",
            "Epoch 3 Batch 100 loss 0.6274794936180115\n",
            "Epoch 3 Batch 200 loss 0.5603978037834167\n",
            "Epoch 3 Batch 300 loss 0.5267680883407593\n",
            "Epoch 3 Batch 400 loss 0.5110331773757935\n",
            "Epoch 3 Batch 500 loss 0.5369577407836914\n",
            "Epoch 3 Batch 600 loss 0.5308071374893188\n",
            "Epoch 3 Batch 700 loss 0.4786403775215149\n",
            "Epoch 3 Loss 0.5430\n",
            "Time taken for 1 epoch 104.8927059173584 sec\n",
            "\n",
            "Epoch 4 Batch 0 loss 0.3762722611427307\n",
            "Epoch 4 Batch 100 loss 0.3930814862251282\n",
            "Epoch 4 Batch 200 loss 0.40432968735694885\n",
            "Epoch 4 Batch 300 loss 0.34421297907829285\n",
            "Epoch 4 Batch 400 loss 0.3839719593524933\n",
            "Epoch 4 Batch 500 loss 0.39218670129776\n",
            "Epoch 4 Batch 600 loss 0.41013890504837036\n",
            "Epoch 4 Batch 700 loss 0.317891389131546\n",
            "Epoch 4 Loss 0.3762\n",
            "Time taken for 1 epoch 106.21084547042847 sec\n",
            "\n",
            "Epoch 5 Batch 0 loss 0.2741304039955139\n",
            "Epoch 5 Batch 100 loss 0.26604196429252625\n",
            "Epoch 5 Batch 200 loss 0.28379693627357483\n",
            "Epoch 5 Batch 300 loss 0.2721514403820038\n",
            "Epoch 5 Batch 400 loss 0.24907660484313965\n",
            "Epoch 5 Batch 500 loss 0.2875541150569916\n",
            "Epoch 5 Batch 600 loss 0.30228543281555176\n",
            "Epoch 5 Batch 700 loss 0.3119409680366516\n",
            "Epoch 5 Loss 0.2723\n",
            "Time taken for 1 epoch 104.95653438568115 sec\n",
            "\n",
            "Epoch 6 Batch 0 loss 0.21941988170146942\n",
            "Epoch 6 Batch 100 loss 0.20861998200416565\n",
            "Epoch 6 Batch 200 loss 0.25552263855934143\n",
            "Epoch 6 Batch 300 loss 0.2374567985534668\n",
            "Epoch 6 Batch 400 loss 0.19475451111793518\n",
            "Epoch 6 Batch 500 loss 0.21332870423793793\n",
            "Epoch 6 Batch 600 loss 0.2389262169599533\n",
            "Epoch 6 Batch 700 loss 0.2135729342699051\n",
            "Epoch 6 Loss 0.2064\n",
            "Time taken for 1 epoch 105.87316060066223 sec\n",
            "\n",
            "Epoch 7 Batch 0 loss 0.17501501739025116\n",
            "Epoch 7 Batch 100 loss 0.12977324426174164\n",
            "Epoch 7 Batch 200 loss 0.13145147264003754\n",
            "Epoch 7 Batch 300 loss 0.13751934468746185\n",
            "Epoch 7 Batch 400 loss 0.16157014667987823\n",
            "Epoch 7 Batch 500 loss 0.15002559125423431\n",
            "Epoch 7 Batch 600 loss 0.18364650011062622\n",
            "Epoch 7 Batch 700 loss 0.1624896079301834\n",
            "Epoch 7 Loss 0.1645\n",
            "Time taken for 1 epoch 104.91502737998962 sec\n",
            "\n",
            "Epoch 8 Batch 0 loss 0.12162947654724121\n",
            "Epoch 8 Batch 100 loss 0.10888984054327011\n",
            "Epoch 8 Batch 200 loss 0.11362569779157639\n",
            "Epoch 8 Batch 300 loss 0.14954248070716858\n",
            "Epoch 8 Batch 400 loss 0.12477371841669083\n",
            "Epoch 8 Batch 500 loss 0.12753550708293915\n",
            "Epoch 8 Batch 600 loss 0.1570833921432495\n",
            "Epoch 8 Batch 700 loss 0.14938770234584808\n",
            "Epoch 8 Loss 0.1382\n",
            "Time taken for 1 epoch 106.06897735595703 sec\n",
            "\n",
            "Epoch 9 Batch 0 loss 0.11162612587213516\n",
            "Epoch 9 Batch 100 loss 0.11742819845676422\n",
            "Epoch 9 Batch 200 loss 0.11494922637939453\n",
            "Epoch 9 Batch 300 loss 0.12534697353839874\n",
            "Epoch 9 Batch 400 loss 0.11668229103088379\n",
            "Epoch 9 Batch 500 loss 0.1111113429069519\n",
            "Epoch 9 Batch 600 loss 0.13427554070949554\n",
            "Epoch 9 Batch 700 loss 0.1397160142660141\n",
            "Epoch 9 Loss 0.1188\n",
            "Time taken for 1 epoch 105.10178112983704 sec\n",
            "\n",
            "Epoch 10 Batch 0 loss 0.09404324740171432\n",
            "Epoch 10 Batch 100 loss 0.07862386107444763\n",
            "Epoch 10 Batch 200 loss 0.09775424748659134\n",
            "Epoch 10 Batch 300 loss 0.09410674124956131\n",
            "Epoch 10 Batch 400 loss 0.11667883396148682\n",
            "Epoch 10 Batch 500 loss 0.1254860907793045\n",
            "Epoch 10 Batch 600 loss 0.09728182852268219\n",
            "Epoch 10 Batch 700 loss 0.12064695358276367\n",
            "Epoch 10 Loss 0.1049\n",
            "Time taken for 1 epoch 105.73225951194763 sec\n",
            "\n",
            "Epoch 11 Batch 0 loss 0.09516770392656326\n",
            "Epoch 11 Batch 100 loss 0.07499440759420395\n",
            "Epoch 11 Batch 200 loss 0.07804729044437408\n",
            "Epoch 11 Batch 300 loss 0.10713227093219757\n",
            "Epoch 11 Batch 400 loss 0.12228405475616455\n",
            "Epoch 11 Batch 500 loss 0.10084688663482666\n",
            "Epoch 11 Batch 600 loss 0.08792375773191452\n",
            "Epoch 11 Batch 700 loss 0.1350601464509964\n",
            "Epoch 11 Loss 0.0949\n",
            "Time taken for 1 epoch 105.03112745285034 sec\n",
            "\n",
            "Epoch 12 Batch 0 loss 0.06723137944936752\n",
            "Epoch 12 Batch 100 loss 0.07016982138156891\n",
            "Epoch 12 Batch 200 loss 0.09514706581830978\n",
            "Epoch 12 Batch 300 loss 0.11308558285236359\n",
            "Epoch 12 Batch 400 loss 0.0902334600687027\n",
            "Epoch 12 Batch 500 loss 0.10027074813842773\n",
            "Epoch 12 Batch 600 loss 0.10305190086364746\n",
            "Epoch 12 Batch 700 loss 0.1038200855255127\n",
            "Epoch 12 Loss 0.0880\n",
            "Time taken for 1 epoch 106.1225357055664 sec\n",
            "\n",
            "Epoch 13 Batch 0 loss 0.0605730302631855\n",
            "Epoch 13 Batch 100 loss 0.08090752363204956\n",
            "Epoch 13 Batch 200 loss 0.08539936691522598\n",
            "Epoch 13 Batch 300 loss 0.05681430920958519\n",
            "Epoch 13 Batch 400 loss 0.10004470497369766\n",
            "Epoch 13 Batch 500 loss 0.08814772218465805\n",
            "Epoch 13 Batch 600 loss 0.07539772242307663\n",
            "Epoch 13 Batch 700 loss 0.10653581470251083\n",
            "Epoch 13 Loss 0.0825\n",
            "Time taken for 1 epoch 104.96070337295532 sec\n",
            "\n",
            "Epoch 14 Batch 0 loss 0.043421726673841476\n",
            "Epoch 14 Batch 100 loss 0.06477289646863937\n",
            "Epoch 14 Batch 200 loss 0.05634596571326256\n",
            "Epoch 14 Batch 300 loss 0.11098776012659073\n",
            "Epoch 14 Batch 400 loss 0.08634021878242493\n",
            "Epoch 14 Batch 500 loss 0.08106040954589844\n",
            "Epoch 14 Batch 600 loss 0.11336515098810196\n",
            "Epoch 14 Batch 700 loss 0.0875902771949768\n",
            "Epoch 14 Loss 0.0775\n",
            "Time taken for 1 epoch 105.92705368995667 sec\n",
            "\n",
            "Epoch 15 Batch 0 loss 0.07110124826431274\n",
            "Epoch 15 Batch 100 loss 0.041223496198654175\n",
            "Epoch 15 Batch 200 loss 0.05444622039794922\n",
            "Epoch 15 Batch 300 loss 0.06505008786916733\n",
            "Epoch 15 Batch 400 loss 0.10002591460943222\n",
            "Epoch 15 Batch 500 loss 0.07823777198791504\n",
            "Epoch 15 Batch 600 loss 0.1028941199183464\n",
            "Epoch 15 Batch 700 loss 0.08139076828956604\n",
            "Epoch 15 Loss 0.0738\n",
            "Time taken for 1 epoch 105.03266072273254 sec\n",
            "\n",
            "Epoch 16 Batch 0 loss 0.05444565415382385\n",
            "Epoch 16 Batch 100 loss 0.07188846915960312\n",
            "Epoch 16 Batch 200 loss 0.0684075802564621\n",
            "Epoch 16 Batch 300 loss 0.07514648884534836\n",
            "Epoch 16 Batch 400 loss 0.07318412512540817\n",
            "Epoch 16 Batch 500 loss 0.08338367193937302\n",
            "Epoch 16 Batch 600 loss 0.08806774020195007\n",
            "Epoch 16 Batch 700 loss 0.07175364345312119\n",
            "Epoch 16 Loss 0.0704\n",
            "Time taken for 1 epoch 106.58367872238159 sec\n",
            "\n",
            "Epoch 17 Batch 0 loss 0.03475581482052803\n",
            "Epoch 17 Batch 100 loss 0.08560547977685928\n",
            "Epoch 17 Batch 200 loss 0.07598443329334259\n",
            "Epoch 17 Batch 300 loss 0.06985687464475632\n",
            "Epoch 17 Batch 400 loss 0.0720338374376297\n",
            "Epoch 17 Batch 500 loss 0.09402012825012207\n",
            "Epoch 17 Batch 600 loss 0.09114306420087814\n",
            "Epoch 17 Batch 700 loss 0.07361949980258942\n",
            "Epoch 17 Loss 0.0676\n",
            "Time taken for 1 epoch 105.49528789520264 sec\n",
            "\n",
            "Epoch 18 Batch 0 loss 0.04619769752025604\n",
            "Epoch 18 Batch 100 loss 0.04613145813345909\n",
            "Epoch 18 Batch 200 loss 0.0681002289056778\n",
            "Epoch 18 Batch 300 loss 0.06708776205778122\n",
            "Epoch 18 Batch 400 loss 0.060449447482824326\n",
            "Epoch 18 Batch 500 loss 0.0761597529053688\n",
            "Epoch 18 Batch 600 loss 0.09869145601987839\n",
            "Epoch 18 Batch 700 loss 0.08625688403844833\n",
            "Epoch 18 Loss 0.0655\n",
            "Time taken for 1 epoch 106.97707033157349 sec\n",
            "\n",
            "Epoch 19 Batch 0 loss 0.033660661429166794\n",
            "Epoch 19 Batch 100 loss 0.045407190918922424\n",
            "Epoch 19 Batch 200 loss 0.06903053820133209\n",
            "Epoch 19 Batch 300 loss 0.06101137399673462\n",
            "Epoch 19 Batch 400 loss 0.07376773655414581\n",
            "Epoch 19 Batch 500 loss 0.07184218615293503\n",
            "Epoch 19 Batch 600 loss 0.08674149960279465\n",
            "Epoch 19 Batch 700 loss 0.08936827629804611\n",
            "Epoch 19 Loss 0.0643\n",
            "Time taken for 1 epoch 105.61589932441711 sec\n",
            "\n",
            "Epoch 20 Batch 0 loss 0.05391345173120499\n",
            "Epoch 20 Batch 100 loss 0.03902849182486534\n",
            "Epoch 20 Batch 200 loss 0.053998567163944244\n",
            "Epoch 20 Batch 300 loss 0.0546271912753582\n",
            "Epoch 20 Batch 400 loss 0.052211958914995193\n",
            "Epoch 20 Batch 500 loss 0.06597622483968735\n",
            "Epoch 20 Batch 600 loss 0.07990928739309311\n",
            "Epoch 20 Batch 700 loss 0.09440808743238449\n",
            "Epoch 20 Loss 0.0623\n",
            "Time taken for 1 epoch 106.72290563583374 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQOJ92iFPFg7"
      },
      "source": [
        "##Translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0QBSDkYPJPH"
      },
      "source": [
        "The evaluate function is similar to the training loop, except we don't use teacher forcing here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "\n",
        "Stop predicting when the model predicts the end token or when the max traget legth is reached\n",
        "\n",
        "And store the attention weights for every time step.\n",
        "\n",
        "Note: The encoder output is calculated only once for one input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny-35UW0UXDD"
      },
      "source": [
        "#Calculating the max length of the source and target sentences\n",
        "max_target_length= max(len(t) for t in  target_tensor)\n",
        "max_source_length= max(len(t) for t in source_tensor)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T68GtWpD9sOs"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_target_length, max_source_length))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  #print(sentence)\n",
        "  #print(source_sentence_tokenizer.word_index)\n",
        "\n",
        "  inputs = [source_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_source_length,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n",
        "\n",
        "  for t in range(max_target_length):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "    if target_sentence_tokenizer.index_word[predicted_id] == '_end':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuG5OXl9PYvH"
      },
      "source": [
        "##To Plot Attention weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPHk1zL_PVqP"
      },
      "source": [
        "#function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGm8vHh9PhFy"
      },
      "source": [
        "def translatee(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "  \n",
        "  #print('Input: %s' % (sentence))\n",
        "  #print('Predicted translation: {}'.format(result))\n",
        "  return result\n",
        "\n",
        " # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        " # plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdWjemoYuiHD"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "  \n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "  \n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC1qOf3xPoUf"
      },
      "source": [
        "##Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g72RuuyFPlFu",
        "outputId": "0be422e9-bfb7-46bf-e295-a29d891a3241"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f16679bfd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khAE_K_uPv3P"
      },
      "source": [
        "##Final translations with Attention Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "_-nO-Ua7PtPf",
        "outputId": "3581ce58-1d24-449b-a040-2a0959747124"
      },
      "source": [
        "translate(u'I am going to work.')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: start_ i am going to work . _end\n",
            "Predicted translation: voy a trabajar . _end \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3cNgfjgUkoV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "65f10409-ecd2-4a1a-af1d-fbed1fa80383"
      },
      "source": [
        "translate(u'You need to work smart.')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: start_ you need to work smart . _end\n",
            "Predicted translation: necesitas trabajar . _end \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoYAAAGeCAYAAAAJ58ASAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZglZXn+8e89CwxL0J9LFBWBGBAluOBIMCogiBowJnGLGxqNIhGNCwTjzs814iSKEEVixBiXaNyIiom7iGFREFEBR5ABQRGURYFhBoYnf9Tb2hzOLGSarjrd38919TV9quqcfrqg69zn3SpVhSRJkrSg7wIkSZI0DAZDSZIkAQZDSZIkNQZDSZIkAQZDSZIkNQZDSZIkAQZDSZIkNQZDSZIkAQZDSZI2SJLXJtl8zPbNkry2j5qkmRbvfDI/JPkesF9V/aTvWiRpEiVZA2xdVZeNbL8jcFlVLeynMmnm2GI4f2wHLO67CEmaYAHGtaY8ELhilmuRbhOL+i5AkqQhS/JrukBYwI+TTA+HC4ElwDF91CbNNIOhJEnr9kK61sL3Aa8Crp62bzWwoqpO7qMwaaYZDCVJWoeq+tcki4AtgOOr6uK+a5JuK44xlCRpParqRuAIuq5jac6yxVCSdDNJdquq09ay7xlV9cHZrmkgTgEeBFzYdyEaniT33NBjq+qi27KWjeFyNRMuyTOBj1bVqpHtmwBPqaoPtMdPo+sCubaHMtWTJF9l/CzKW6iqvW/jcjQhklwG7FFV545sPwA4pqq26KeyfiV5CvBm4J3A6cDNrqdVdUYfdWkYktzEhl9vB9vybDCccK6rpXVJctS0hwuBpwOXAqe2bbsBWwMfrKqDZ7k8DVSSlwMHA380NZ6ufQh9N/AXVfXZPuvrS3vjX5vyeju/JXnQtIc70g09OAaYmpj0EOD5wMur6iOzXN4GMxhOuHahuktVXT6y/YHAl6vqDv1UpqFJ8na6cPjimvaHn+QddNeCF/dWnAYnyTLgscDDgP3pQuGTqupzvRbWoyTbrmt/VdnFLACSfB04qqo+PrL9iXTX4If3U9n6GQwnVLuTSQE7Az8Ebpy2eyGwLXBCVT25h/I0QEl+CTykqpaPbN8ROMUPERqV5DhgD+CudKHwhJ5LkiZCkpXA/ddyvT2zqm5xa8WhcPLJ5Jr6FPIHwOeAa6btWw2sAD4xyzVp2ALsAiwf2b5LD7VoYJI8fszmE4B9gI8AS6aOqapPzmZtQ9KWrdkNuCewyfR9U2O6Jbr34BcALxnZ/gIGPnnJFsMJ1i5Qzwc+XVWX9F2Phq11Df4V8Fa62ZUAuwOHAcdV1SF91ab+rWf83HTzdixdkp2AzwDb033QWkPXwHIDsKqqtuqxPA1IkscAn6ILgVPX2z+kuz3t46vq8z2Vtl4GwwmX5Hpgp6pa0XctGrYkC4BDgRfTTTgB+BlwJPAPVbWmr9qkSZDkv4Cr6D5gXQo8ALgd3fjLV1fVF3ssTwOT5B50LYQ7tU3n0M3q/0l/Va2fwXDCJTkVeFVVfanvWjQ5kmwFUFW/6rsWDUuSxcBJwDOr6od91zMkbZzunlX1/SRXA7tV1Q+T7Ek30eB+PZcobTTHGE6+w4F/SPI6xq+rdUUfRfUpycvWtb+q/nG2ahmiJEuBewGfbY+3oOsGu3GdT9S8UFU3JNmeDVyPbZ4JcF37/nLg7nST/y4Gfr+vojRMSTana1X+XUbuNDfkcbq2GE64kXFB0/9jhnk6FijJBSObFtN1na6kW9vx92a/qv4luQtwPN3A+QJ2qKofJ3kPcL3L1WhKkrcBVNXf9l3LkCQ5EXh7VX0qyYeBO9IteP084H62GGpKkkfSTdq645jdg35vtsVw8j2i7wKGpqq2H93WQtFxwD/PfkWD8Xbg53QXqum3Y/oP4Kixz9B8tQXw9CT7Mr4n4m96qap/b6I7NwCvplsR4qvALwCXBtN0R9L9//HKqvpp38XcGrYYat5oi35/rKp26LuWPiT5ObBPGx/1a7o1tn7cug2/P19vc6ZbardSXJvy9om/leQOwJXlm6mmSXItXSvy+X3XcmvZYjhHJLkb49fVOrGfigZpAXCXvovo0WZ0a1yOujNw/SzXogGrKnsiNtB8HMetDfJN4N6AwVCzqwXCD9PdnaBoYwunHTLYcQy3lTEL9YZujOHBwDdmv6LBOBH4S+CV7XElWQi8HPhyX0VpuJIsoZtUUcD5VTWvP0Ak2ZRu+ZFHMH5CwW591KVBOgZY1t6jv0e31uVvVNUZvVS1AexKnnBJPkY3Zuxg4FvAY+haxV4PvHQ+rqs1ZqHeoptB+BXgkKr62exX1b8k9wW+DpwJ7Ek3K3lnunXYHjqJXR66bbQla94MvJCuFyLAKrqxqK+qqhvW8fQ5K8kH6O4ffTzdeN2bvYFW1Sv6qEvDs54F4518otvUnsD+VXVukgIur6pvJlkFvAGYd8Gwqhas/6j5p6rOTrILXYvHKmAJ3cSTf5qvYVlr9VbgqcBBdGsaAjwceAtdK9mhPdXVt8cBf1pVX++7EA3eLSZBTgpbDCdckl/RDXBdkWQF8IyqOqlNKPjBkG/ULWmYklwKPKeqThjZvj/w3qraevwz57Yky4E/r6of9F2LdFuxZWXynctvb7dzJnBQkm3pupbn7f2Tk+yf5MQkv0hyeZKvJ9mv77r6lmSXJEcnOSHJ1m3bn7UZ29KU2zF+0Pz5wO1nuZYheSXw5iT/r+9CNHxJ/jjJZ5OcnWSbtu25Sfbpu7Z1MRhOviOBu7bvXw88CvgxXXfhK9f2pLksyXPpbl5+Pt3Eir8DLgA+leQ5fdbWpySPohuHendgH7pZytDdBeV1fdWlQfouMG6twhfTfQCdr74AbA5cluQnSX48/avv4jQcSZ4OfAz4EV238uK2ayFwWF91bQi7kueYdguenYCLquoXfdfThyQ/Ao6sqqNHtr8IeFFV7dhPZf1q99X+16p618g6hg8CPlNVd+u5xN44+/bmkuwBnEDX63BK27w7cDfgj6vqpLU9dy5L8mngwXQrQYybfPIPfdSl4UnyXeAtVfXvI9fb+wNfqKrBLp1mMJxwSV4LLKuq60a2bwb8bVW9vp/K+tMm3uxcVeeNbP99unGXm/ZTWb/agqs7t/Goowtcn1NVS3oucdYlWUQ3ocLZtyPaMhsvAO7TNp0DvGvS7uIwk9rf0N5VdWrftWjYklwH3KeqLhy53t6L7oYCm63nJXpjV/Lkex2w5ZjtmzN/uwcvAvYds/1RwIWzXMuQXEHXjTxqV+DiWa5lKI4AnkE3+3ZHYAfgr4ED6ALjvJTkC8Cz6FoN/6KqnlBVr57PobC5iO6Dg7Q+P6W7pozag4Eveu1yNZNvdEHrKQ+kCwLz0TLgqCS7Av/Ttj2U7s3+Rb1V1b8PA29L8mS6/2cWJdmT7nwd12tl/Xkat5x9e36Sy4H3Mn+XZTkN2I/uw+UNSU4Gvta+TquqG/srrVcvBY5I8oLRHglpxLHAO9uYd4Btkjyc7sPo4b1VtQHsSp5QrWm66G7ofh23vNvJEuCYqjq4h/J6l+TPgUO4eTfY26rq+P6q6ldbtPj9wFPoPlDcRNdr8CHg2fPxzT7JSuABVfXDke07Ad8ZcnfPbGhDUv4I2Kt9/SFwfVVt1WNZvWnX3U3prrGrgJv9zczX86LxkryJ7sPE1DCdVXRDv14z7Zh7AD+tqnUtiD2rDIYTKsmz6N7c3we8BLh62u7VwIqqOrmP2vrWBoi/FzhhSH9sQ5Hk9+i6jxfQhZ8f9VxSb5KcApw++gEqybvpAuND+qlsGJLchS4Q7k13G7h7AKfO13spt+vuWlXVv85WLZoMbULofemut2dX1TUj+39Fd60ZzKx2u5In1NQFKMkWwIlV9b32eF+6sUE/SHJaVa3pscy+XAt8FLg6yfuB99nt00nyF3RL1Uzd5/UZSQCoqsf1WFpfDgNOSPJIxsy+7a2qniV5F10g3BY4le5Wis8DTqmq+TzG7lvAmqkW5mnX27Pp7hYj3UybGPrtdRyS2aplQzn5ZPIdQHe/W9oCmp8G7kC3wPUbe6yrN1X1dGBrulsCPhJY3ha7fmbrGpuXkrwN+CCwHXAV8MuRr/loBd0A8Y/TTeLaku42gfemm2gwXx1Edw/2v6cLz6+vqq/P81AIXQ/NA+EW19sXME+vt5p77EqecEmuAnarquVJXgo8rqoekeQRwHFVtV2/FfYvyc7Ac+ne7FbRtSa+o6rO6bWwWZbk58DBVfXxvmsZiiRrgK2r6rKR7XcELhvyje5vS21Jjb3a157A79DdM/mrwNeq6ozeiuuR11vNtOlL2fRdyxRbDCffQroxhdB1EU7NrjwfGOwCmrOlrcX2p8Bj6QaKfwLYBjgryXybcbqA+X3XinHWNqt/S2DeLnJdVedX1b9U1QFVdU/gIcDldC2I3+q3ul55vdWc5xjDyfd94K+TfJbuQvWKtv3uwHy988liujD4HLr1DL9Dt0TAR6YG/iZ5HPABuqVa5otj6dbsO7znOnqX5J3t2wLe0hajnbIQ2I15HKKTLACW0k042YtuuaclwOl0S9bMV15vNdMG121rMJx8L6cb53Io3e3Ovte2P45uLbL56Gd0LUEfBv6uqs4ac8yJwJWzWlX/bg88rQ2YPwu42V09qmrcvXHnql3av6Fb0mj1tH2rgTOYXx8aRl1FtyzLGXRB8B3ASVV1bZ9FDYDX21spyTnADlVl3hhvcJNPHGM4ByRZCGxVVVdO27YdcN3o2Kn5IMkBwH/M9/vdjkry1XXsrqrae9aKGYgkxwEvrqpf9V3LkCR5NAbBsbze3jpJXgjcsar+f9+1DFGbxPTTIa0gYjCUJEkS4OQTSZIkNQZDSZIkAQbDOSfJgX3XMDSek/E8L+N5XsbzvNyS52Q8z8t4k3JeDIZzz0T8jzfLPCfjeV7G87yM53m5Jc/JeJ6X8SbivBgMJUmSBDgreUZskiW12YIt+y4DgNV1PZtkSd9lAFCbbdp3CQDccMO1LF68Rd9lALB6q+F8Fltz3bUs3HwY52XRyuFch25cdS2LNh3GeVlww3DOy5D+joZiSOckq1av/6BZsvqm69lkwUDeh24czCow3MAqFjOM98Vfc+UvqurO4/a54OQM2GzBluy+2f59lzE4a+6/Q98lDM5PHjWMN5GhufOZN/ZdwiBt9rOVfZcwTAsGtyZw7xaed0nfJQzSmiuu6ruEQfrSmo9euLZ9w2m+kCRJUq8MhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWomPhgmOTzJ9/uuQ5IkadJNfDAElgF7Tj1I8v4kn+2xHkmSpIm0qO8CNlZVXQNc03cdkiRJk269LYZJvpbkXUnenOQXSS5LsizJgrZ/kyRvTXJxkuuSfCvJo0deY6ck/5nk6iTXJDk5yS7T9j87ydlJrk+yPMlLp16/7X9+2359q+G/kyxq+37TlZzkcOBZwP5Jqn3t1fb9fZIfJlmZZEWSI5IsmfYztklyfJIr2u9xbpKnbMzJlSRJmiQb2mL4dOBI4I+ABwAfBk4HPgIcB9wLeBpwMbAf8JkkD66q7ya5G3AS8E1gX+AqYDdgIUCS5wGvB17UXvMPgH8GbgCOTrIU+Ce6wHcScHtg77XUuQy4D3AH4IC27Yr277XAc4BLgPsCxwCrgNe0/e8ClgCPAH4F3HsDz40kSdKcsKHB8Oyqem37fnkLc/skOQ14KrBdVV3U9h+d5JHA84EXAAfThbInVdXqqdeY9tqvAQ6rqo+3xxck+fv23KOBe7bn/2dV/Rq4EPjuuCKr6pokK4FVVXXpyL43THu4IsmbgUP5bTDcFvhEVU299gXrOiFJDgQOBFiSLdZ1qCRJ0kTY0GB41sjjnwK/C+wKBDg7yfT9mwJfad8/EDhpWij8jSR3BrYB3pPk3SN1Tb3gF+nC4AVJ/hv4AvDJFhI3WJInAi8Bfh/Ykq7FcuG0Q44EjknyGODLwKeq6vS1vV5VHQscC3C7hXeqW1OLJEnSEG3orOQbRh5Xe+6C9v2D6bqYp77uQ9dtu6E//6CR5/8BsDNAC4C7Ak8GLgJeAZzbuqg3SJLdgX8H/hv4E7qw+mpg8W9+oap/Aban6xrfEfifNmZRkiRpXtjY5Wq+Q9eyd9eqOm/k65JpxzwsySajT66qn9O1Pt5rzPPPm3bcjVX1lap6BXA/YAvgsWupaTU3bwkEeChwSVW9oaq+VVU/ous6Hq3n4qo6tqqeDLyW1lUsSZI0H2zUcjVVtTzJh4D3JzkEOINu4sdewI+r6pN0kzoOAj6W5E3AlXQtjOdU1ZnA64CjklwFnEDXircrcPeqekuSx9JNbjmRbiLJI4DfAc5ZS1krgD9Ocm/gl8DVdGMa757k6cDJwKPpxkb+RpIjgc+3Y7cCHgOcvTHnR5IkaZLMxALXz6brfj0COBf4LLAH3bhAWsvhHsAmwFfpWhBfBNzY9r+Xrtv5ALpJJd+ga6mbmvxxFfBnwJfa6x8KPLeqvrGWev6ZLjR+G7gceGhVfQZ4G/AOuvGS+9K1CE63ADiKLgx+Efg53UxoSZKkeSFVzpvYWLdbeKfafbP9+y5jcNbcf4e+SxicnzzKGezj3PnMG/suYZA2+9nKvksYpgVZ/zHzzMLzLln/QfPQmiuu6ruEQfrSmo+eXlVLx+2bC7fEkyRJ0gwwGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAkwGEqSJKkxGEqSJAmARX0XMBfUTTdx08qVfZcxOAvOOLfvEgbnHgvv03cJg7Rw1Zq+SxikCw/ru4JhusN/bN53CYOz5WlX9V3CMN3kteXWssVQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJgMFQkiRJjcFQkiRJwICDYZIVSQ7dyNfYK0kludNM1SVJkjRXzWgwTPK1JEfP5GtupP8BtgZ+2XchkiRJQzfrLYZJFs/Wz6qq1VV1aVXV//U1kmwykzVJkiQN1YwFwyTvB/YEDm7dt5XkL9u/+yU5Lclq4NFJ7pXk+CSXJrk2yRlJHjvmZbdM8sEk17RjDx35mS9LclZ7jUuSvDfJ7aftv1lXcpI7JvlIkouTrEzygyTPHnnNryV5d5JlSS4HvjlT50iSJGnIZrLF8MXAycBxdN23WwM/afveCrwa2Ak4FdgS+DywL3B/4BPAJ5PsNPKaLwPOAXYFXge8Ocnjp+2/CXgJsDPwNGA34Kh11LgEOAN4bHvOkcB7kuwzctwzgAAPB565/l9dkiRp8i2aqReqqqtbi+B1VXUpwLSgd3hVfWHa4ZcD3532+E1J/gR4IvDGadtPrao3te+XJ3kwXVj8ZPuZ75h27IokhwHHJ3lWVd00psZLgLdN23Rskr2BpwJfnrb9gqo6ZF2/b5IDgQMBlrD5ug6VJEmaCLM1xvDb0x8k2SLJEUnOTnJlkmuApcA9R5538pjH9532Onsn+WLrGv41XWDcBLjruCKSLEzyqtb9/Mv2cx8/5ueevr5fqKqOraqlVbV0MZuu73BJkqTBm61geO3I42XAk4DX0I1LfABwGl2o2yBJtgU+R9fV/CTgQcBz2u61vc6hwCF0rYb7tJ/76THHj9YrSZI0581YV3KzGli4Acc9DPhAVX0CIMkS4F7A8pHjdh/z+Jz2/VK6QPfSqlrTXmfcBJbRn/uZqvq3dnyAHYGrNqBmSZKkOW2mWwxXALsl2a7NBF7b6y8H/jzJrkl2AT5INzFk1O5JXpFkhyTPo5sI8va270ft9V+SZPskT6WbiLIuy4F9kjysjX88Gtj+1vyCkiRJc9VMB8NldK2GZ9NNMBkduzflZcBlwDfoZief0r4f9Y/A/YDv0E1KeW1VfRygqs6imwn9svbznkvXVbwub6Trsv48cCJdl/GHNuxXkyRJmttmtCu5qpYDDxnZ/P4xx10IPHJk87KRY7bbgJ/3TuCdI5s/Nu37qVkh17bjr6SbbLKu19xrfT9XkiRpLhrsvZI3VpK7AH8KnF9VK/uuR5IkaehmevLJkJwA/A5wUN+FSJIkTYI5Gwyr6kF91yBJkjRJ5mxXsiRJkm4dg6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAWNR3AXNGVd8VDE6tWtV3CYOz4KQz+y5hkPzrGW/7V/5e3yUM0glf/7e+Sxic/f5rj75LGKSbfB8a7/q177LFUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSYDBUJIkSY3BUJIkSQAs6ruASZXkQOBAgCVs3nM1kiRJG88Ww/+jqjq2qpZW1dLFbNp3OZIkSRvNYChJkiTAYChJkqTGYLgOSV6Y5Ny+65AkSZoNBsN1uxNw776LkCRJmg0Gw3WoqsOrKn3XIUmSNBsMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQIMhpIkSWoMhpIkSQJgUd8FSJLGW3PeBX2XMEj77fOkvksYnBXv27TvEgZpu9fd0HcJw/T9te+yxVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwVCSJEmAwVCSJEmNwXAtkixNUkm267sWSZKk2WAwlCRJEmAwlCRJUjPxwTCdw5Kcn2Rlku8leca0/du1LuEnJPlikuuSnJ1k35HXeUySc5Ncn+QbwI6z/stIkiT1aOKDIfBG4K+Ag4H7Am8B3pNk/5Hj3gS8E7g/8C3g35NsCZBkG+DTwBeBBwBHAUfMSvWSJEkDsajvAjZGki2AlwGPqqpvtM0XJNmNLih+btrhb6+qz7TnvRJ4Jl0IPAn4a+Ai4G+qqoBzk+wIvGEdP/tA4ECAJWw+o7+XJElSHyY6GNK1EC4B/itJTdu+GFgxcuxZ077/afv3d9u/9wFOaaFwysnr+sFVdSxwLMBWuUOt61hJkqRJMOnBcKor/E/oWvymu2Ftj6uqkkx/viRJ0rw36cHwbGAVsG1VfWUjXucc4AlJMq3VcPeNrk6SJGmCTHQwrKpfJ1kGLEvXBHgisCVdqLupdfduiGOAQ4B3JHkXsAtw0G1RsyRJ0lDNha7U1wCHA4cCP6CbWfwE4IINfYGqugh4PPAY4LvAS4G/m+lCJUmShmyiWwyhGy9It7zMUWvZvwLImO0Zefw5bj6LGeBDM1OlJEnS8M2FFkNJkiTNgMG3GCa5J90kk7W5b+sKliRJ0kYYfDCkW3PwAevZL0mSpI00+GBYVTcC5/VdhyRJ0lznGENJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBsKjvAiRJa1HVdwWDtOacH/VdwuBs88S+KximNX0XMIFsMZQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVJjMJQkSRJgMJQkSVKzqO8CJlWSA4EDAZawec/VSJIkbTxbDP+PqurYqlpaVUsXs2nf5UiSJG00g6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIagx80afoAAAEoSURBVKEkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIAg6EkSZIag6EkSZIASFX1XcPES3I5cGHfdTR3An7RdxED4zkZz/MynudlPM/LLXlOxvO8jDek87JtVd153A6D4RyT5NtVtbTvOobEczKe52U8z8t4npdb8pyM53kZb1LOi13JkiRJAgyGkiRJagyGc8+xfRcwQJ6T8Twv43lexvO83JLnZDzPy3gTcV4cYyhJkiTAFkNJkiQ1BkNJkiQBBkNJkiQ1BkNJkiQBBkNJkiQ1/wu6vXJ0jHcw0QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xE0MBGycVz1q",
        "outputId": "92584ac5-f44c-4f57-d16c-7486e0c17935"
      },
      "source": [
        "translatee(u'tom may have been sick.')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tom pudo haber sido enfermo . _end '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2MrGCWIuZZf"
      },
      "source": [
        "###Calculating the bleu score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AgRgnKWV6Mi",
        "outputId": "9ae7531c-cdc7-4722-ad00-484b4d96e717"
      },
      "source": [
        "print('Cumulative 1-gram: %f' % sentence_bleu(act, pred, weights=(1, 0, 0, 0)))\n",
        "print('Cumulative 2-gram: %f' % sentence_bleu(act, pred, weights=(0.5, 0.5, 0, 0)))\n",
        "print('Cumulative 3-gram: %f' % sentence_bleu(act, pred, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('Cumulative 4-gram: %f' % sentence_bleu(act, pred, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cumulative 1-gram: 0.428571\n",
            "Cumulative 2-gram: 0.654654\n",
            "Cumulative 3-gram: 0.756080\n",
            "Cumulative 4-gram: 0.809107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SEwQ30DnysO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}