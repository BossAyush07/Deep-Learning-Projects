{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "AMZN_CH (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BossAyush07/Deep-Learning-Projects/blob/master/AMZN_CH_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDYQKd0LO5fu",
        "outputId": "48c9b3c4-966b-4a4f-ba16-8c78b674ca2d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('mydrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at mydrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Jt4P0NNCJf"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "UJNk6zPuNRul",
        "outputId": "e708db04-2ae2-40d6-dca7-7dc13646bfce"
      },
      "source": [
        "df = pd.read_csv('/content/mydrive/MyDrive/AMZN_ML_CHALLENGE/sample50')\n",
        "df.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>node</th>\n",
              "      <th>level_1</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>708239</td>\n",
              "      <td>disney princess jasmine fashion doll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2788330</td>\n",
              "      <td>mattel disney princess fairytale magiclip cind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2375629</td>\n",
              "      <td>barbie princess doll assortment  barbie prince...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1891769</td>\n",
              "      <td>mini lalaloopsy doll keys sharps n flatsproduc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2665110</td>\n",
              "      <td>piece baby doll care accessories bagyou  pie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>900829</td>\n",
              "      <td>little mommy sweet party shimmer baby doll mon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>245950</td>\n",
              "      <td>barbie designer collecton gold label anna sui ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>131048</td>\n",
              "      <td>barbie doll world landmark collection big ben ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>506733</td>\n",
              "      <td>alimrose aurelie linen cat doll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1683057</td>\n",
              "      <td>ever high bunny blanc doll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>799934</td>\n",
              "      <td>barbie tea party doll  multi colorbarbie tea p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1836200</td>\n",
              "      <td>barbie doll   multi color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>894819</td>\n",
              "      <td>renewed  barbie dreamtopia sweetville princes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1656410</td>\n",
              "      <td>smart picks beautiful fashion doll set outfit ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>1433594</td>\n",
              "      <td>nicery reborn baby doll soft simulation silico...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  ...                                               text\n",
              "0            0  ...               disney princess jasmine fashion doll\n",
              "1            1  ...  mattel disney princess fairytale magiclip cind...\n",
              "2            2  ...  barbie princess doll assortment  barbie prince...\n",
              "3            3  ...  mini lalaloopsy doll keys sharps n flatsproduc...\n",
              "4            4  ...    piece baby doll care accessories bagyou  pie...\n",
              "5            5  ...  little mommy sweet party shimmer baby doll mon...\n",
              "6            6  ...  barbie designer collecton gold label anna sui ...\n",
              "7            7  ...  barbie doll world landmark collection big ben ...\n",
              "8            8  ...                  alimrose aurelie linen cat doll  \n",
              "9            9  ...                         ever high bunny blanc doll\n",
              "10          10  ...  barbie tea party doll  multi colorbarbie tea p...\n",
              "11          11  ...                          barbie doll   multi color\n",
              "12          12  ...   renewed  barbie dreamtopia sweetville princes...\n",
              "13          13  ...  smart picks beautiful fashion doll set outfit ...\n",
              "14          14  ...  nicery reborn baby doll soft simulation silico...\n",
              "\n",
              "[15 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVKCAEoBvCTJ",
        "outputId": "7d02029e-09e7-4359-88b7-ffe9e3d4a6b5"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "node          0\n",
              "level_1       0\n",
              "text          1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysG5y89cx0I4"
      },
      "source": [
        "df = df.dropna(axis = 0, how ='any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7kP-z0OW0-A",
        "outputId": "f6b50370-843a-4fa8-b049-328230a41247"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(268516, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg1eVL-POYLJ"
      },
      "source": [
        "train_data, test_data = train_test_split(df, test_size=0.01, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3xjl6LSNCxd"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/mydrive/MyDrive/AMZN_ML_CHALLENGE/tokenizer (4).pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkmKiHxIQKWB",
        "outputId": "970ea549-4c86-414f-c542-7747f3a3476c"
      },
      "source": [
        "with open('/content/mydrive/MyDrive/AMZN_ML_CHALLENGE/encoder.pkl', 'rb') as enc_file:\n",
        "    enc = pickle.load(enc_file) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMhajpWCN_y_"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 100\n",
        "batch_size = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcIXbeF2OTEp"
      },
      "source": [
        "def batch_generator(x, y, batch_size=32):\n",
        "    n_samples = len(x)\n",
        "    i=0\n",
        "    while True:\n",
        "        x_batch, y_batch = [], []\n",
        "        for b in range(batch_size):\n",
        "            if i == n_samples:\n",
        "                i = 0\n",
        "            X = tokenizer.texts_to_sequences([' '.join(x[i].split())])\n",
        "            \n",
        "            X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "            Y = np.asarray(y[i])\n",
        "            x_batch.append(np.array(X[0] , dtype = np.float))\n",
        "            y_batch.append(Y)\n",
        "            \n",
        "            i+=1\n",
        "        yield np.array(x_batch), enc.transform(np.array(y_batch).reshape(-1, 1)).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvUL4RnbOez3"
      },
      "source": [
        "train_gen = batch_generator(train_data['text'].values, train_data['node'].values, batch_size)\n",
        "test_gen = batch_generator(test_data['text'].values, test_data['node'].values, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGugHi1Py6wS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3MrvVOCy_Bw"
      },
      "source": [
        "### Downloading the glove pretrained embeddings\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAsIZXdKbmqZ"
      },
      "source": [
        "#!wget https://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gbt8gGmdm2z",
        "outputId": "59777992-da52-4ac3-a91f-c9864ba8c781"
      },
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-31 16:28:58--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-07-31 16:28:58--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.03MB/s    in 2m 40s  \n",
            "\n",
            "2021-07-31 16:31:38 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E84cfFkCfCaE",
        "outputId": "7cbca687-a515-43c5-b83f-2b856a9c4e59"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n51yCO2TfA2f"
      },
      "source": [
        "### Loading the embedding into the memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "666Hsiqfy6s7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab62908a-8205-4e94-fa4c-493aebb2bd4b"
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('/content/glove.6B.100d.txt')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s2RRVE_zQxs"
      },
      "source": [
        "### embedding matrix by assigning the vocabulary with the pretrained word embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysKsRSeCffx5",
        "outputId": "62ce307a-33cf-4784-cad5-6ca4be2599c3"
      },
      "source": [
        "max_features = 100000\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "967294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-qet2oGy6qL"
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ESyzxqy6f4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPE50OVFOjiv"
      },
      "source": [
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, Embedding\n",
        "from keras.models import Model\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "max_features = 100000\n",
        "EMBEDDING_DIM = 100\n",
        "N_CLASSES = 9919\n",
        "\n",
        "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "\n",
        "embedding_layer = Embedding(vocab_size, EMBEDDING_DIM, weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "\n",
        "average = GlobalAveragePooling1D()(embedded_sequences)\n",
        "predictions = Dense(N_CLASSES, activation='softmax')(average)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK5IAJmNOoub",
        "outputId": "e34ae0aa-0f41-4db2-85d3-8fb61308a466"
      },
      "source": [
        "model.fit(train_gen, epochs=50, validation_data=test_gen, steps_per_epoch = len(train_data)//batch_size, validation_steps=len(test_data) // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1038/1038 [==============================] - 60s 44ms/step - loss: 8.9912 - acc: 0.0049 - val_loss: 8.6601 - val_acc: 0.0316\n",
            "Epoch 2/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 8.5479 - acc: 0.0415 - val_loss: 8.3899 - val_acc: 0.0750\n",
            "Epoch 3/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 8.2780 - acc: 0.0801 - val_loss: 8.1662 - val_acc: 0.0934\n",
            "Epoch 4/50\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 8.0404 - acc: 0.1064 - val_loss: 7.9742 - val_acc: 0.1051\n",
            "Epoch 5/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 7.8284 - acc: 0.1268 - val_loss: 7.7962 - val_acc: 0.1227\n",
            "Epoch 6/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 7.6367 - acc: 0.1431 - val_loss: 7.6472 - val_acc: 0.1352\n",
            "Epoch 7/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 7.4629 - acc: 0.1566 - val_loss: 7.4783 - val_acc: 0.1488\n",
            "Epoch 8/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 7.3031 - acc: 0.1683 - val_loss: 7.3552 - val_acc: 0.1605\n",
            "Epoch 9/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 7.1569 - acc: 0.1789 - val_loss: 7.2198 - val_acc: 0.1621\n",
            "Epoch 10/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 7.0216 - acc: 0.1886 - val_loss: 7.1059 - val_acc: 0.1715\n",
            "Epoch 11/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 6.8967 - acc: 0.1971 - val_loss: 7.0099 - val_acc: 0.1750\n",
            "Epoch 12/50\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 6.7801 - acc: 0.2051 - val_loss: 6.9341 - val_acc: 0.1793\n",
            "Epoch 13/50\n",
            "1038/1038 [==============================] - 46s 45ms/step - loss: 6.6706 - acc: 0.2123 - val_loss: 6.8180 - val_acc: 0.1867\n",
            "Epoch 14/50\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 6.5685 - acc: 0.2189 - val_loss: 6.7256 - val_acc: 0.1934\n",
            "Epoch 15/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 6.4729 - acc: 0.2250 - val_loss: 6.6455 - val_acc: 0.1988\n",
            "Epoch 16/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 6.3814 - acc: 0.2306 - val_loss: 6.5699 - val_acc: 0.2031\n",
            "Epoch 17/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 6.2953 - acc: 0.2363 - val_loss: 6.4942 - val_acc: 0.2039\n",
            "Epoch 18/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 6.2144 - acc: 0.2414 - val_loss: 6.4428 - val_acc: 0.2027\n",
            "Epoch 19/50\n",
            "1038/1038 [==============================] - 46s 45ms/step - loss: 6.1370 - acc: 0.2466 - val_loss: 6.3723 - val_acc: 0.2094\n",
            "Epoch 20/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 6.0635 - acc: 0.2511 - val_loss: 6.3142 - val_acc: 0.2070\n",
            "Epoch 21/50\n",
            "1038/1038 [==============================] - 46s 45ms/step - loss: 5.9936 - acc: 0.2556 - val_loss: 6.2592 - val_acc: 0.2098\n",
            "Epoch 22/50\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 5.9273 - acc: 0.2597 - val_loss: 6.2152 - val_acc: 0.2129\n",
            "Epoch 23/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 5.8635 - acc: 0.2638 - val_loss: 6.1159 - val_acc: 0.2207\n",
            "Epoch 24/50\n",
            "1038/1038 [==============================] - 47s 45ms/step - loss: 5.8041 - acc: 0.2677 - val_loss: 6.0934 - val_acc: 0.2227\n",
            "Epoch 25/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 5.7468 - acc: 0.2714 - val_loss: 6.0428 - val_acc: 0.2219\n",
            "Epoch 26/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 5.6921 - acc: 0.2750 - val_loss: 6.0126 - val_acc: 0.2215\n",
            "Epoch 27/50\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 5.6387 - acc: 0.2787 - val_loss: 5.9711 - val_acc: 0.2230\n",
            "Epoch 28/50\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 5.5877 - acc: 0.2822 - val_loss: 5.9042 - val_acc: 0.2313\n",
            "Epoch 29/50\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 5.5384 - acc: 0.2859 - val_loss: 5.8862 - val_acc: 0.2301\n",
            "Epoch 30/50\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 5.4928 - acc: 0.2889 - val_loss: 5.8200 - val_acc: 0.2309\n",
            "Epoch 31/50\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 5.4478 - acc: 0.2921 - val_loss: 5.8073 - val_acc: 0.2352\n",
            "Epoch 32/50\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 5.4035 - acc: 0.2948 - val_loss: 5.7691 - val_acc: 0.2355\n",
            "Epoch 33/50\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 5.3619 - acc: 0.2976 - val_loss: 5.7580 - val_acc: 0.2383\n",
            "Epoch 34/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 5.3211 - acc: 0.3006 - val_loss: 5.7087 - val_acc: 0.2375\n",
            "Epoch 35/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 5.2822 - acc: 0.3034 - val_loss: 5.6633 - val_acc: 0.2375\n",
            "Epoch 36/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 5.2435 - acc: 0.3062 - val_loss: 5.6442 - val_acc: 0.2441\n",
            "Epoch 37/50\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 5.2065 - acc: 0.3089 - val_loss: 5.6120 - val_acc: 0.2445\n",
            "Epoch 38/50\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 5.1708 - acc: 0.3118 - val_loss: 5.5992 - val_acc: 0.2434\n",
            "Epoch 39/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 5.1355 - acc: 0.3144 - val_loss: 5.5685 - val_acc: 0.2453\n",
            "Epoch 40/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 5.1006 - acc: 0.3173 - val_loss: 5.5309 - val_acc: 0.2488\n",
            "Epoch 41/50\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 5.0686 - acc: 0.3194 - val_loss: 5.5284 - val_acc: 0.2477\n",
            "Epoch 42/50\n",
            "1038/1038 [==============================] - 47s 46ms/step - loss: 5.0378 - acc: 0.3219 - val_loss: 5.4888 - val_acc: 0.2496\n",
            "Epoch 43/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 5.0080 - acc: 0.3240 - val_loss: 5.4794 - val_acc: 0.2535\n",
            "Epoch 44/50\n",
            "1038/1038 [==============================] - 47s 45ms/step - loss: 4.9790 - acc: 0.3261 - val_loss: 5.4311 - val_acc: 0.2574\n",
            "Epoch 45/50\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 4.9494 - acc: 0.3283 - val_loss: 5.4117 - val_acc: 0.2602\n",
            "Epoch 46/50\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.9213 - acc: 0.3304 - val_loss: 5.4004 - val_acc: 0.2582\n",
            "Epoch 47/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 4.8939 - acc: 0.3325 - val_loss: 5.3972 - val_acc: 0.2562\n",
            "Epoch 48/50\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 4.8668 - acc: 0.3347 - val_loss: 5.3592 - val_acc: 0.2633\n",
            "Epoch 49/50\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.8405 - acc: 0.3365 - val_loss: 5.3342 - val_acc: 0.2656\n",
            "Epoch 50/50\n",
            "1038/1038 [==============================] - 47s 45ms/step - loss: 4.8146 - acc: 0.3388 - val_loss: 5.3207 - val_acc: 0.2625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe0bc817750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLc_XRf_wZZH",
        "outputId": "babcae19-04dd-4f2d-e2e6-0f0e51b52b8e"
      },
      "source": [
        "model.fit(train_gen, epochs=25, validation_data=test_gen, steps_per_epoch = len(train_data)//batch_size, validation_steps=len(test_data) // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 4.7857 - acc: 0.3421 - val_loss: 5.2618 - val_acc: 0.2676\n",
            "Epoch 2/25\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.7615 - acc: 0.3440 - val_loss: 5.3079 - val_acc: 0.2648\n",
            "Epoch 3/25\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 4.7376 - acc: 0.3459 - val_loss: 5.2683 - val_acc: 0.2684\n",
            "Epoch 4/25\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.7145 - acc: 0.3478 - val_loss: 5.2719 - val_acc: 0.2652\n",
            "Epoch 5/25\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.6918 - acc: 0.3497 - val_loss: 5.2193 - val_acc: 0.2688\n",
            "Epoch 6/25\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.6694 - acc: 0.3515 - val_loss: 5.2146 - val_acc: 0.2695\n",
            "Epoch 7/25\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 4.6478 - acc: 0.3534 - val_loss: 5.1998 - val_acc: 0.2738\n",
            "Epoch 8/25\n",
            "1038/1038 [==============================] - 46s 45ms/step - loss: 4.6265 - acc: 0.3553 - val_loss: 5.1794 - val_acc: 0.2734\n",
            "Epoch 9/25\n",
            "1038/1038 [==============================] - 46s 45ms/step - loss: 4.6057 - acc: 0.3571 - val_loss: 5.1936 - val_acc: 0.2695\n",
            "Epoch 10/25\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.5852 - acc: 0.3587 - val_loss: 5.1612 - val_acc: 0.2758\n",
            "Epoch 11/25\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.5651 - acc: 0.3603 - val_loss: 5.1446 - val_acc: 0.2703\n",
            "Epoch 12/25\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.5455 - acc: 0.3621 - val_loss: 5.1516 - val_acc: 0.2734\n",
            "Epoch 13/25\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 4.5264 - acc: 0.3639 - val_loss: 5.1230 - val_acc: 0.2777\n",
            "Epoch 14/25\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.5077 - acc: 0.3657 - val_loss: 5.1047 - val_acc: 0.2805\n",
            "Epoch 15/25\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.4891 - acc: 0.3674 - val_loss: 5.0745 - val_acc: 0.2832\n",
            "Epoch 16/25\n",
            "1038/1038 [==============================] - 45s 44ms/step - loss: 4.4710 - acc: 0.3689 - val_loss: 5.0827 - val_acc: 0.2828\n",
            "Epoch 17/25\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.4532 - acc: 0.3706 - val_loss: 5.0764 - val_acc: 0.2816\n",
            "Epoch 18/25\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.4356 - acc: 0.3720 - val_loss: 5.0771 - val_acc: 0.2805\n",
            "Epoch 19/25\n",
            "1038/1038 [==============================] - 43s 42ms/step - loss: 4.4184 - acc: 0.3736 - val_loss: 5.0271 - val_acc: 0.2891\n",
            "Epoch 20/25\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.4018 - acc: 0.3751 - val_loss: 5.0423 - val_acc: 0.2859\n",
            "Epoch 21/25\n",
            "1038/1038 [==============================] - 46s 44ms/step - loss: 4.3851 - acc: 0.3767 - val_loss: 5.0032 - val_acc: 0.2859\n",
            "Epoch 22/25\n",
            "1038/1038 [==============================] - 43s 42ms/step - loss: 4.3689 - acc: 0.3782 - val_loss: 4.9970 - val_acc: 0.2879\n",
            "Epoch 23/25\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.3527 - acc: 0.3798 - val_loss: 5.0047 - val_acc: 0.2863\n",
            "Epoch 24/25\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.3373 - acc: 0.3811 - val_loss: 5.0227 - val_acc: 0.2836\n",
            "Epoch 25/25\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.3216 - acc: 0.3827 - val_loss: 4.9856 - val_acc: 0.2867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe05f641d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ6m4NRMlWhH",
        "outputId": "e80a9177-d4a5-43da-fb97-b5985aea1594"
      },
      "source": [
        "model.fit(train_gen, epochs=30, validation_data=test_gen, steps_per_epoch = len(train_data)//batch_size, validation_steps=len(test_data) // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.3065 - acc: 0.3842 - val_loss: 4.9621 - val_acc: 0.2855\n",
            "Epoch 2/30\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.2915 - acc: 0.3856 - val_loss: 4.9580 - val_acc: 0.2902\n",
            "Epoch 3/30\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.2768 - acc: 0.3868 - val_loss: 4.9524 - val_acc: 0.2898\n",
            "Epoch 4/30\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.2621 - acc: 0.3882 - val_loss: 4.9361 - val_acc: 0.2914\n",
            "Epoch 5/30\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.2481 - acc: 0.3895 - val_loss: 4.9447 - val_acc: 0.2883\n",
            "Epoch 6/30\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 4.2339 - acc: 0.3906 - val_loss: 4.9218 - val_acc: 0.2922\n",
            "Epoch 7/30\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.2201 - acc: 0.3920 - val_loss: 4.9410 - val_acc: 0.2855\n",
            "Epoch 8/30\n",
            "1038/1038 [==============================] - 43s 41ms/step - loss: 4.2067 - acc: 0.3933 - val_loss: 4.9245 - val_acc: 0.2906\n",
            "Epoch 9/30\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.1931 - acc: 0.3944 - val_loss: 4.9179 - val_acc: 0.2906\n",
            "Epoch 10/30\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.1797 - acc: 0.3959 - val_loss: 4.8636 - val_acc: 0.2953\n",
            "Epoch 11/30\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.1668 - acc: 0.3971 - val_loss: 4.8866 - val_acc: 0.2945\n",
            "Epoch 12/30\n",
            "1038/1038 [==============================] - 43s 42ms/step - loss: 4.1539 - acc: 0.3983 - val_loss: 4.8738 - val_acc: 0.2926\n",
            "Epoch 13/30\n",
            "1038/1038 [==============================] - 43s 41ms/step - loss: 4.1413 - acc: 0.3996 - val_loss: 4.8850 - val_acc: 0.2922\n",
            "Epoch 14/30\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.1290 - acc: 0.4008 - val_loss: 4.8718 - val_acc: 0.2934\n",
            "Epoch 15/30\n",
            "1038/1038 [==============================] - 43s 41ms/step - loss: 4.1165 - acc: 0.4020 - val_loss: 4.8404 - val_acc: 0.2977\n",
            "Epoch 16/30\n",
            "1038/1038 [==============================] - 43s 41ms/step - loss: 4.1043 - acc: 0.4032 - val_loss: 4.8606 - val_acc: 0.2941\n",
            "Epoch 17/30\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.0923 - acc: 0.4045 - val_loss: 4.8123 - val_acc: 0.2969\n",
            "Epoch 18/30\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.0805 - acc: 0.4055 - val_loss: 4.8371 - val_acc: 0.2965\n",
            "Epoch 19/30\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.0688 - acc: 0.4067 - val_loss: 4.8223 - val_acc: 0.2937\n",
            "Epoch 20/30\n",
            "1038/1038 [==============================] - 43s 41ms/step - loss: 4.0575 - acc: 0.4078 - val_loss: 4.8422 - val_acc: 0.2930\n",
            "Epoch 21/30\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.0461 - acc: 0.4089 - val_loss: 4.8191 - val_acc: 0.2926\n",
            "Epoch 22/30\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.0348 - acc: 0.4100 - val_loss: 4.7932 - val_acc: 0.2941\n",
            "Epoch 23/30\n",
            "1038/1038 [==============================] - 43s 41ms/step - loss: 4.0236 - acc: 0.4112 - val_loss: 4.8030 - val_acc: 0.2961\n",
            "Epoch 24/30\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 4.0127 - acc: 0.4123 - val_loss: 4.7900 - val_acc: 0.2957\n",
            "Epoch 25/30\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 4.0019 - acc: 0.4135 - val_loss: 4.8040 - val_acc: 0.2945\n",
            "Epoch 26/30\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 3.9913 - acc: 0.4144 - val_loss: 4.7813 - val_acc: 0.2969\n",
            "Epoch 27/30\n",
            "1038/1038 [==============================] - 43s 42ms/step - loss: 3.9809 - acc: 0.4155 - val_loss: 4.7693 - val_acc: 0.2945\n",
            "Epoch 28/30\n",
            "1038/1038 [==============================] - 44s 43ms/step - loss: 3.9703 - acc: 0.4166 - val_loss: 4.7929 - val_acc: 0.2941\n",
            "Epoch 29/30\n",
            "1038/1038 [==============================] - 45s 43ms/step - loss: 3.9601 - acc: 0.4178 - val_loss: 4.7666 - val_acc: 0.2965\n",
            "Epoch 30/30\n",
            "1038/1038 [==============================] - 44s 42ms/step - loss: 3.9500 - acc: 0.4189 - val_loss: 4.7689 - val_acc: 0.2988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe0b028ded0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC-AxVzwvjEy"
      },
      "source": [
        "### Setting up for predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYiZG5LdqRDn"
      },
      "source": [
        " test_df = pd.read_csv('/content/mydrive/MyDrive/AMZN_ML_CHALLENGE/prepared_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTzm7Mpjvexz"
      },
      "source": [
        "x_batch, y_batch = [], []\n",
        "for i in range(len(test_df['text'].values)):\n",
        "    X = tokenizer.texts_to_sequences([test_df['text'].values[i]])\n",
        "    X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    x_batch.append(np.array(X[0] , dtype = np.float))\n",
        "\n",
        "X = np.array(x_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1jDASfNvfI2"
      },
      "source": [
        "predictions = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SHRhe4kvp4w",
        "outputId": "530aa67d-e6d6-43f5-948f-3aac4e5a2297"
      },
      "source": [
        "for i in range(0, len(X), 100):\n",
        "\n",
        "    if i%1000==0:\n",
        "        print(i)\n",
        "    y_pp = model.predict(X[i:i+100])\n",
        "    y_p = list(enc.inverse_transform(y_pp).reshape(-1))\n",
        "    predictions += y_p"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n",
            "74000\n",
            "75000\n",
            "76000\n",
            "77000\n",
            "78000\n",
            "79000\n",
            "80000\n",
            "81000\n",
            "82000\n",
            "83000\n",
            "84000\n",
            "85000\n",
            "86000\n",
            "87000\n",
            "88000\n",
            "89000\n",
            "90000\n",
            "91000\n",
            "92000\n",
            "93000\n",
            "94000\n",
            "95000\n",
            "96000\n",
            "97000\n",
            "98000\n",
            "99000\n",
            "100000\n",
            "101000\n",
            "102000\n",
            "103000\n",
            "104000\n",
            "105000\n",
            "106000\n",
            "107000\n",
            "108000\n",
            "109000\n",
            "110000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEQVY3nnvqbJ"
      },
      "source": [
        "sub = pd.DataFrame()\n",
        "sub['PRODUCT_ID'] = list(range(len(predictions)))\n",
        "sub['BROWSE_NODE_ID'] = predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rp1FiOlvtbZ"
      },
      "source": [
        "sub.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2c3D7HYw86Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}